{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWYgEHnE8W/tm6mcCAU2Gw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchenley/Portfolio/blob/main/Volterra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCmRcHFqZA5r"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "from torchvision.utils import make_grid\n",
        "from torchsummary import summary\n",
        " \n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.preprocessing as skp\n",
        "from scipy import signal as sp\n",
        "from scipy import interpolate as interp\n",
        "from scipy.special import factorial\n",
        "import seaborn as sb\n",
        "\n",
        "import itertools\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "import os\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAic_-x1RGrY"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyaF217ca04F"
      },
      "outputs": [],
      "source": [
        "class LaguerreFilterbank(torch.nn.Module):\n",
        "  def __init__(self, \n",
        "               num_filters = 3, \n",
        "               a_init = 0.5, a_train = True,\n",
        "               dt = 1,\n",
        "               dtype = torch.float32, device = device):\n",
        "    super(LaguerreFilterbank, self).__init__()\n",
        "\n",
        "    a_init = torch.tensor(a_init).to(device = device, dtype = dtype)\n",
        "\n",
        "    a = torch.nn.Parameter(a_init, requires_grad = a_train)\n",
        "    \n",
        "    self.num_filters = num_filters\n",
        "    self.a_train = a_train\n",
        "    self.a = a\n",
        "    self.dt = dt\n",
        "\n",
        "    self.dtype, self.device = dtype, device\n",
        "\n",
        "  def forward(self, X, v = None):\n",
        "    \n",
        "    N = X.shape[0]\n",
        "    V = torch.zeros((N, self.num_filters)).to(device = self.device, dtype = self.dtype)\n",
        "\n",
        "    if v is None:\n",
        "      v = torch.zeros((1, self.num_filters)).to(device = self.device, dtype = self.dtype)\n",
        "\n",
        "    for n in range(N):\n",
        "\n",
        "      # 0th order DLF\n",
        "      V[n:(n+1), 0:1] = torch.sqrt(self.a)*v[:, 0:1] + self.dt*torch.sqrt(1-self.a)*X[n:(n+1)]\n",
        "      #\n",
        "      \n",
        "      # ith order DLFs\n",
        "      for j in range(1, self.num_filters):    \n",
        "        v_i_j = torch.sqrt(self.a)*(v[:,j:(j+1)] + V[n:(n+1),(j-1):j]) - v[:,(j-1):j]\n",
        "        V[n:(n+1), j:(j+1)] = v_i_j\n",
        "      #\n",
        "    \n",
        "      v = V[n:(n+1)]\n",
        "\n",
        "    return V, v\n",
        "\n",
        "  def basis(self):\n",
        "\n",
        "    with torch.inference_mode(): \n",
        "\n",
        "      b = torch.empty((0, self.num_filters)).to(device = self.device, dtype = self.dtype)\n",
        "      v = torch.zeros((1, self.num_filters)).to(device = self.device, dtype = self.dtype)\n",
        "       \n",
        "      v_n, _ = self(X = torch.ones((1, 1)).to(device = self.device, dtype = self.dtype), \n",
        "                    v = v)\n",
        "      \n",
        "      while (v_n[-1, :].abs() > 1e-4).any():      \n",
        "        b = torch.cat((b, v_n), axis = 0)\n",
        "        \n",
        "        v_n, _ = self(X = torch.zeros((1, 1)).to(device = self.device, dtype = self.dtype), \n",
        "                      v = v_n) \n",
        "        \n",
        "    return b\n",
        "\n",
        "  def conv(self, X):\n",
        "\n",
        "    if type(X) is not torch.Tensor:\n",
        "      X = torch.tensor(X).to(device = self.device, dtype = self.dtype)\n",
        "\n",
        "    b = self.basis()\n",
        "    \n",
        "    M = b.shape[0]\n",
        "    X_ = X.T.unsqueeze(0)\n",
        "    b_ = b.flip(dims = [0]).T.unsqueeze(dim = 1)         \n",
        "    V =  torch.nn.functional.conv1d(X_, b_,\n",
        "                                    bias=None, \n",
        "                                    stride=1, padding = M-1, \n",
        "                                    dilation=1, groups=1).mT.reshape(-1, self.num_filters)[:X.shape[0], :]\n",
        "\n",
        "    return V\n",
        "    "
      ]
    }
  ]
}